{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential \n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "IMG_WIDTH=30\n",
    "IMG_HEIGHT=30\n",
    "NUM_CATEGORIES=43\n",
    "TEST_SIZE=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"C:\\\\Users\\\\jasmin olabi\\\\.conda\\\\envs\\\\tf\\\\Lib\\\\site-packages\\\\traffic\\\\gtsrb\"):\n",
    "    \"\"\"\n",
    "    Load image data from directory `data_dir`.\n",
    "\n",
    "    Assume `data_dir` has one directory named after each category, numbered\n",
    "    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n",
    "    number of image files.\n",
    "\n",
    "    Return tuple `(images, labels)`. `images` should be a list of all\n",
    "    of the images in the data directory, where each image is formatted as a\n",
    "    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n",
    "    be a list of integer labels, representing the categories for each of the\n",
    "    corresponding `images`.\n",
    "    \"\"\"\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    \n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if not file.startswith('.'):\n",
    "                # Read in and resize image\n",
    "                img = cv2.imread(os.path.join(root, file))\n",
    "                img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "                # Add current image and label to output lists\n",
    "                images.append(img)\n",
    "                labels.append(int(os.path.basename(root)))\n",
    "\n",
    "    return (images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    Returns a compiled convolutional neural network model. Assume that the\n",
    "    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n",
    "    The output layer should have `NUM_CATEGORIES` units, one for each category.\n",
    "    \"\"\"\n",
    "    # Create a convolutional neural network\n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "        # Convolutional layer. Learn 32 filters using a 3x3 kernel\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, (3, 3), activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "        ),\n",
    "\n",
    "        # Max-pooling layer, using 2x2 pool size\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # 2nd convolutional layer. Learn 32 filters using a 3x3 kernel\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, (3, 3), activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "        ),\n",
    "\n",
    "        # Flatten units\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        # Add a hidden layer with dropout\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "        # Add an output layer with output unit for all categories\n",
    "        tf.keras.layers.Dense(NUM_CATEGORIES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    # Train neural network\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Check command-line arguments\n",
    "    if len(sys.argv) not in [1, 3]:\n",
    "        sys.exit(\"Usage: python traffic.py data_directory [model.h5]\")\n",
    "\n",
    "    # Get image arrays and labels for all image files\n",
    "    images, labels = load_data(\"C:\\\\Users\\\\jasmin olabi\\\\.conda\\\\envs\\\\tf\\\\Lib\\\\site-packages\\\\traffic\\\\gtsrb\")\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    labels = tf.keras.utils.to_categorical(labels,NUM_CATEGORIES)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
    "    )\n",
    "\n",
    "    # Get a compiled neural network\n",
    "    model = get_model()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "\n",
    "    # Fit model on training data\n",
    "    model.fit(x_train, y_train, epochs=EPOCHS)\n",
    "\n",
    "    # Evaluate neural network performance\n",
    "    model.evaluate(x_test,  y_test, verbose=2)\n",
    "    \n",
    "    print(len(sys.argv))\n",
    "\n",
    "    # Save model to file\n",
    "    if len(sys.argv) == 1:\n",
    "        filename = 'C:\\\\Users\\\\jasmin olabi\\\\.conda\\\\envs\\\\tf\\\\Lib\\\\site-packages'\n",
    "        model.save(\"model\",saved_format=\"h5\")\n",
    "        print(f\"Model Saved to {filename},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 43)                5547      \n",
      "=================================================================\n",
      "Total params: 605,643\n",
      "Trainable params: 605,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "15984/15984 [==============================] - 18s 1ms/sample - loss: 3.3253 - acc: 0.2594\n",
      "Epoch 2/10\n",
      "15984/15984 [==============================] - 19s 1ms/sample - loss: 1.6673 - acc: 0.4966\n",
      "Epoch 3/10\n",
      "15984/15984 [==============================] - 17s 1ms/sample - loss: 1.2351 - acc: 0.6081\n",
      "Epoch 4/10\n",
      "15984/15984 [==============================] - 17s 1ms/sample - loss: 0.9830 - acc: 0.6891\n",
      "Epoch 5/10\n",
      "15984/15984 [==============================] - 20s 1ms/sample - loss: 0.7635 - acc: 0.7623\n",
      "Epoch 6/10\n",
      "15984/15984 [==============================] - 16s 1ms/sample - loss: 0.6263 - acc: 0.8016\n",
      "Epoch 7/10\n",
      "15984/15984 [==============================] - 15s 963us/sample - loss: 0.5379 - acc: 0.8303\n",
      "Epoch 8/10\n",
      "15984/15984 [==============================] - 16s 974us/sample - loss: 0.4309 - acc: 0.8666\n",
      "Epoch 9/10\n",
      "15984/15984 [==============================] - 14s 889us/sample - loss: 0.3624 - acc: 0.8908\n",
      "Epoch 10/10\n",
      "15984/15984 [==============================] - 14s 870us/sample - loss: 0.3185 - acc: 0.9052\n",
      "10656/10656 - 2s - loss: 0.1399 - acc: 0.9648\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
