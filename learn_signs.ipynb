{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential \n",
    "from keras.datasets import mnist\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "IMG_WIDTH=30\n",
    "IMG_HEIGHT=30\n",
    "NUM_CATEGORIES=43\n",
    "TEST_SIZE=0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    \"\"\"\n",
    "    Load image data from directory `data_dir`.\n",
    "\n",
    "    Assume `data_dir` has one directory named after each category, numbered\n",
    "    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n",
    "    number of image files.\n",
    "\n",
    "    Return tuple `(images, labels)`. `images` should be a list of all\n",
    "    of the images in the data directory, where each image is formatted as a\n",
    "    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n",
    "    be a list of integer labels, representing the categories for each of the\n",
    "    corresponding `images`.\n",
    "    \"\"\"\n",
    "    \n",
    "    images=[]\n",
    "    labels=[]\n",
    "    \n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if not file.startswith('.'):\n",
    "                # Read in and resize image\n",
    "                img = cv2.imread(os.path.join(root, file))\n",
    "                img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "                # Add current image and label to output lists\n",
    "                images.append(img)\n",
    "                labels.append(int(os.path.basename(root)))\n",
    "\n",
    "    return (images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "        # Convolutional layer. Learn 32 filters using a 3x3 kernel\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, (3, 3), activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "        ),\n",
    "\n",
    "        # Max-pooling layer, using 2x2 pool size\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # 2nd convolutional layer. Learn 32 filters using a 3x3 kernel\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, (3, 3), activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "        ),\n",
    "\n",
    "        # Flatten units\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        # Add a hidden layer with dropout\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "        # Add an output layer with output unit for all categories\n",
    "        tf.keras.layers.Dense(NUM_CATEGORIES, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    # Train neural network\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # Check command-line arguments\n",
    "    if len(sys.argv) not in [1, 3]:\n",
    "        sys.exit(\"Usage: python traffic.py data_directory [model.h5]\")\n",
    "\n",
    "    # Get image arrays and labels for all image files\n",
    "    images, labels = load_data('C:\\\\Users\\\\jasmin olabi\\\\.conda\\\\envs\\\\tf\\\\Lib\\\\site-packages\\\\traffic\\\\gtsrb')\n",
    "    # Split data into training and testing sets\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(np.array(images), np.array(labels), test_size=TEST_SIZE)\n",
    "    \n",
    "   \n",
    "     \n",
    "    # Get a compiled neural network\n",
    "    model = get_model()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "    #Add checkpoint\n",
    "    checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.h5',verbose=1,save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max')\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=2,monitor='val_loss'),\n",
    "              tf.keras.callbacks.TensorBoard(log_dir='logs')]\n",
    "\n",
    "\n",
    "    # Fit model on training data\n",
    "    #validation_split allows  to automatically reserve part of  training data for validation which use 20%\n",
    "    model.fit(x_train, y_train, batch_size=16, validation_split=0.2, epochs=EPOCHS,callbacks=callbacks)\n",
    "\n",
    "\n",
    "    # Evaluate neural network performance\n",
    "    model.evaluate(x_test,  y_test, verbose=2)\n",
    "    \n",
    "    print(len(sys.argv))\n",
    "\n",
    "    # Save model to file\n",
    "    if len(sys.argv) == 1:\n",
    "        filename = 'C:\\\\Users\\\\jasmin olabi\\\\.conda\\\\envs\\\\tf\\\\Lib\\\\site-packages'\n",
    "        model.save(\"filename.h5\")\n",
    "        print(f\"Model Saved to {filename},\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 43)                5547      \n",
      "=================================================================\n",
      "Total params: 605,643\n",
      "Trainable params: 605,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 43)                5547      \n",
      "=================================================================\n",
      "Total params: 605,643\n",
      "Trainable params: 605,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 19180 samples, validate on 4796 samples\n",
      "Epoch 1/10\n",
      "19180/19180 [==============================] - 27s 1ms/sample - loss: 1.9041 - acc: 0.5538 - val_loss: 0.6104 - val_acc: 0.8492\n",
      "Epoch 2/10\n",
      "19180/19180 [==============================] - 27s 1ms/sample - loss: 0.7482 - acc: 0.7985 - val_loss: 0.3775 - val_acc: 0.9053\n",
      "Epoch 3/10\n",
      "19180/19180 [==============================] - 27s 1ms/sample - loss: 0.5552 - acc: 0.8443 - val_loss: 0.2626 - val_acc: 0.9374\n",
      "Epoch 4/10\n",
      "19180/19180 [==============================] - 27s 1ms/sample - loss: 0.4569 - acc: 0.8758 - val_loss: 0.2498 - val_acc: 0.9391\n",
      "Epoch 5/10\n",
      "19180/19180 [==============================] - 25s 1ms/sample - loss: 0.4009 - acc: 0.8922 - val_loss: 0.2187 - val_acc: 0.9402\n",
      "Epoch 6/10\n",
      "19180/19180 [==============================] - 27s 1ms/sample - loss: 0.3689 - acc: 0.9020 - val_loss: 0.2366 - val_acc: 0.9508\n",
      "Epoch 7/10\n",
      "19180/19180 [==============================] - 35s 2ms/sample - loss: 0.3370 - acc: 0.9092 - val_loss: 0.2083 - val_acc: 0.9529\n",
      "Epoch 8/10\n",
      "19180/19180 [==============================] - 29s 2ms/sample - loss: 0.3371 - acc: 0.9132 - val_loss: 0.1816 - val_acc: 0.9575\n",
      "Epoch 9/10\n",
      "19180/19180 [==============================] - 27s 1ms/sample - loss: 0.3142 - acc: 0.9205 - val_loss: 0.1692 - val_acc: 0.9627\n",
      "Epoch 10/10\n",
      "19180/19180 [==============================] - 26s 1ms/sample - loss: 0.2823 - acc: 0.9266 - val_loss: 0.2113 - val_acc: 0.9581\n",
      "2664/2664 - 1s - loss: 0.3111 - acc: 0.9512\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.plot(['accuracy'], label='training accuracy')\n",
    "plt.plot(['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
